# -*- coding: utf-8 -*-
"""Logistic Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PlpZQutsf7SgjdmxxlyOI--Pqzz3lJtM
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, roc_curve
)

sns.set(style="whitegrid", palette="coolwarm")
plt.rcParams['figure.figsize'] = (8, 5)

train_df = pd.read_csv('/content/Titanic_train.csv')
test_df = pd.read_csv('/content/Titanic_test.csv')

print("‚úÖ Datasets Loaded Successfully!")
print("Training shape:", train_df.shape)
print("Testing shape:", test_df.shape)

# Combine temporarily for consistent preprocessing
df = pd.concat([train_df, test_df], sort=False)

# 3Ô∏è‚É£ Exploratory Data Analysis (EDA)
print("\nBasic Info:")
df.info()

print("\nSummary Statistics:")
display(df.describe())

# Missing values
print("\nMissing Values:")
print(df.isnull().sum())

# Visualize target variable (Survival)
if 'Survived' in df.columns:
    sns.countplot(x='Survived', data=train_df, palette='coolwarm')
    plt.title("Distribution of Survival")
    plt.show()

# Distribution of Age and Fare
for col in ['Age', 'Fare']:
    plt.figure(figsize=(7,4))
    sns.histplot(df[col], kde=True, bins=30, color='skyblue')
    plt.title(f"Distribution of {col}")
    plt.show()

# Survival rate by gender and class
if 'Survived' in train_df.columns:
    plt.figure(figsize=(6,4))
    sns.barplot(x='Sex', y='Survived', data=train_df, ci=None)
    plt.title("Survival Rate by Gender")
    plt.show()

    plt.figure(figsize=(6,4))
    sns.barplot(x='Pclass', y='Survived', data=train_df, ci=None)
    plt.title("Survival Rate by Passenger Class")
    plt.show()

# 4Ô∏è‚É£ Data Preprocessing

# Fill missing numerical values with median
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Fare'].fillna(df['Fare'].median(), inplace=True)

# Fill categorical missing values
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Encode categorical variables
df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})
df = pd.get_dummies(df, columns=['Embarked', 'Pclass'], drop_first=True)

# Feature selection (common relevant columns)
features = ['Sex', 'Age', 'Fare', 'SibSp', 'Parch',
            'Embarked_Q', 'Embarked_S', 'Pclass_2', 'Pclass_3']

# Split again into train/test using the known target column
train_clean = df[df['Survived'].notna()].copy()
test_clean = df[df['Survived'].isna()].copy()

X = train_clean[features]
y = train_clean['Survived']

# Train-test split (80-20)
X_train, X_valid, y_train, y_valid = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_valid_scaled = scaler.transform(X_valid)

# 5Ô∏è‚É£ Model Building ‚Äî Logistic Regression
log_reg = LogisticRegression(max_iter=1000, random_state=42)
log_reg.fit(X_train_scaled, y_train)

# Predictions
y_pred = log_reg.predict(X_valid_scaled)
y_prob = log_reg.predict_proba(X_valid_scaled)[:, 1]

# 6Ô∏è‚É£ Model Evaluation
acc = accuracy_score(y_valid, y_pred)
prec = precision_score(y_valid, y_pred)
rec = recall_score(y_valid, y_pred)
f1 = f1_score(y_valid, y_pred)
roc_auc = roc_auc_score(y_valid, y_prob)

print("\nüìä MODEL PERFORMANCE METRICS:")
print(f"Accuracy  : {acc:.4f}")
print(f"Precision : {prec:.4f}")
print(f"Recall    : {rec:.4f}")
print(f"F1 Score  : {f1:.4f}")
print(f"ROC-AUC   : {roc_auc:.4f}")

# Confusion Matrix
cm = confusion_matrix(y_valid, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_valid, y_prob)
plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
plt.plot([0,1],[0,1],'r--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

# 7Ô∏è‚É£ Interpretation of Coefficients
coef_df = pd.DataFrame({
    'Feature': features,
    'Coefficient': log_reg.coef_[0]
}).sort_values(by='Coefficient', ascending=False)

print("\nüîç Feature Importance (Logistic Coefficients):")
display(coef_df)

print("""
üí° INTERPRETATION:
Positive coefficients ‚Üí increase survival probability.
Negative coefficients ‚Üí decrease survival probability.
E.g., being female (Sex=1) has a positive coefficient, meaning higher survival chances.
Higher class or higher fare also positively influence survival.
""")

# 8Ô∏è‚É£ Optional ‚Äî Save model for Streamlit deployment
import joblib
joblib.dump((log_reg, scaler, features), 'titanic_logistic_model.pkl')
print("\nüíæ Model saved as 'titanic_logistic_model.pkl' for Streamlit deployment.")